{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8876343-af09-4992-ac9d-0332db0e97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from typing import Tuple\n",
    "from functools import cache\n",
    "import itertools\n",
    "import scipy.special\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = (16,9)\n",
    "matplotlib.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c919185-05f9-41d9-96a1-d25afb4c6878",
   "metadata": {},
   "source": [
    "# An implementation of artifact statistics\n",
    "This code aims to demonstrate the ideas and maths shown in the following paper: [https://www.overleaf.com/read/nvxmkdpqjprj](https://www.overleaf.com/read/nvxmkdpqjprj)\n",
    "\n",
    "I offer three contributions:\n",
    "\n",
    "1. Very fast implementation of GenshinOptimizer's existing Roll Probability Calculator. frzyc noted that it's somewhat straining the front-end, so I've made a cache-based implementation that runs in microseconds per query.\n",
    "2. A method that, given an optimization target and a current build, finds the artifact in the inventory that has the greatest chance of improving your build.\n",
    "3. A method to evaluate any particular build by scoring how difficult it would be to improve any item of the build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e9f651-dff8-4e04-9d1d-4c30d3ebbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def nk3(n, k):\n",
    "    return sum([scipy.special.binom(n, i) * scipy.special.binom(n, k-2*i) for i in range(k//2+1)])\n",
    "\n",
    "@cache\n",
    "def mu(a, j):\n",
    "    return sum([nk3(j, i-7*j) for i in range(a, 10*j+1)]) / (4**j)\n",
    "\n",
    "@cache\n",
    "def multinom(j1, j2=None, j3=None, j4=None, N=5):\n",
    "    # The standard multinomial distribution. Below logic handles variable arguments\n",
    "    if j2 is None:\n",
    "        rem = N-j1\n",
    "        rv = scipy.stats.multinomial(N, [1/4, 3/4])\n",
    "        return rv.pmf([j1, rem])\n",
    "    \n",
    "    if j3 is None:\n",
    "        rem = N-j1-j2\n",
    "        rv = scipy.stats.multinomial(N, [1/4, 1/4, 2/4])\n",
    "        return rv.pmf([j1, j2, rem])\n",
    "    \n",
    "    if j4 is None:\n",
    "        rem = N-j1-j2-j3\n",
    "        rv = scipy.stats.multinomial(N, [1/4, 1/4, 1/4, 1/4])\n",
    "        return rv.pmf([j1, j2, j3, rem])\n",
    "    \n",
    "    if j1+j2+j3+j4 != N:\n",
    "        return 0\n",
    "    rv = scipy.stats.multinomial(N, [1/4, 1/4, 1/4, 1/4])\n",
    "    return rv.pmf([j1, j2, j3, j4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2c1a8-ebba-4a6d-8b0c-a2e729c041df",
   "metadata": {},
   "source": [
    "## Type 1 Query (Contribution 1)\n",
    "The type 1 query behaves as:\n",
    "$$ P(A_1\\geq a_1 \\land A_2\\geq a_2\\land\\cdots)$$\n",
    "\n",
    "This is already implemented in frzyc's GenshinOptimizer, but issues regarding its computational load have been brought up. The following method I present is quite fast; with appropriate caching it reaches about 200µs per loop. (around .2s for 1000 queries)\n",
    "\n",
    "----\n",
    "\n",
    "Can be further optimized:\n",
    "- iterate with nested loops i=0..N; j=0..(N-i); k=0..(N-i-j) rather than the cartesian products\n",
    "- check for mu=0 conditions, whenever $a_i> 10(j_i+b)$. Skip computation of those terms.\n",
    "- wrap the cached functions in a preprocessor to reduce required cache size\n",
    "  - mu=1 whenever $a_i \\leq 7(j_i+b)$\n",
    "  - sort inputs to `multinom`, discard any zeros in the input\n",
    "- sort the inputs (a1, a2, ...) and additionally cache `prob1` based on their inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2464a40-eacb-4722-8fbc-e074b87049e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A1 >= a1 AND A2 >= a2)\n",
    "def prob1(a1, a2=None, a3=None, a4=None, N=5, b=1):\n",
    "    if a2 is None:\n",
    "        return sum([multinom(j1, N=N) * mu(a1, j1+b) for j1 in range(N+1)])\n",
    "    \n",
    "    if a3 is None:\n",
    "        ret = 0\n",
    "        for j1, j2 in filter(lambda x: sum(x)<=N, itertools.product(range(N+1), repeat=2)):\n",
    "            ret += multinom(j1, j2, N=N) * mu(a1, j1+b) * mu(a2, j2+b)\n",
    "        return ret\n",
    "    \n",
    "    if a4 is None:\n",
    "        ret = 0\n",
    "        for j1, j2, j3 in filter(lambda x: sum(x)<=N, itertools.product(range(N+1), repeat=3)):\n",
    "            ret += multinom(j1, j2, j3, N=N) * mu(a1, j1+b) * mu(a2, j2+b) * mu(a3, j3+b)\n",
    "        return ret\n",
    "    \n",
    "    ret = 0\n",
    "    for j1, j2, j3 in filter(lambda x: sum(x)<=N, itertools.product(range(N+1), repeat=3)):\n",
    "        j4 = N-j1-j2-j3\n",
    "        ret += multinom(j1, j2, j3, j4, N=N) * mu(a1, j1+b) * mu(a2, j2+b) * mu(a3, j3+b) * mu(a4, j4+b)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b346573d-b228-4cdd-bfd6-ce5194af6797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 µs ± 6.94 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit prob1(*np.random.randint(20, size=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba580290-f393-4ca8-9ef0-12725205fdab",
   "metadata": {},
   "source": [
    "### Type 1 Query on existing artifact\n",
    "Existing artifacts reduce to a special case of the previous query. Since they're practically the same query, the runtime is essentially the same, and is faster if `rolls_left` is smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3981983e-6b5f-4e26-b624-caae18c40527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1_existing(requirements, existing, rolls_left):\n",
    "    transformed_requirements = []\n",
    "    for ai, az in zip(requirements, existing):\n",
    "        transformed_requirements.append(ai - az)\n",
    "    \n",
    "    return prob1(*transformed_requirements, N=rolls_left, b=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8d6f8-423f-42ba-b25e-bc61ba63ddd0",
   "metadata": {},
   "source": [
    "## Type 2 Query\n",
    "The type 2 query behaves as:\n",
    "$$ P(k_1A_1 + k_2A_2 + \\cdots\\geq a^*)$$\n",
    "\n",
    "There are many reasons why this kind of query is interesting. For example, suppose I want my artifact to roll 100 EM or 15% crit rate, or anywhere in between. So some acceptable results would be:\n",
    "- 100 EM, 0% cr\n",
    "- 90 EM, 1.5% cr\n",
    "- 80 EM, 3% cr\n",
    "- 50 EM, 7.5% cr\n",
    "- 20 EM, 12% cr\n",
    "- 0 EM, 25% cr\n",
    "\n",
    "Converting to the language of substat rolls, we're asking for 42.9 IVs in EM or 38.6 IVs in CR. Writing with linear coefficients, we can roughly phrase the problem as:\n",
    "$$ \\begin{array}{ccc}k_1 = 0.9 & k_2 = 1 & a^* = 38.6 \\end{array} $$\n",
    "$$ P(0.9A_1 + A_2 \\geq 38.6) $$\n",
    "\n",
    "\n",
    "The problem becomes rather nontrivial even for the combination of only two artifacts, especially when they have different weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875606bd-1a0c-4e0b-8dd0-ed6f82b6398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of (v, p(v)) which represent exact distribution of P(k1A1 + ... = v)\n",
    "def exact(ks, js):\n",
    "    if len(ks) == 0:\n",
    "        return np.array([[0, 1]])\n",
    "    \n",
    "    k, j = ks[-1], js[-1]\n",
    "    pr1 = np.array([(k*i, nk3(j, i-7*j) / 4**j) for i in range(7*j, 10*j+1)])\n",
    "    pr2 = exact(ks[:-1], js[:-1])\n",
    "    \n",
    "    res = {}\n",
    "    for v1, p1 in pr1:\n",
    "        for v2, p2 in pr2:\n",
    "            res[v1 + v2] = res.get(v1+v2, 0) + p1*p2\n",
    "    return np.array([(k, v) for k, v in res.items()])\n",
    "\n",
    "# Returns the probability the sum total value of k1A1 + ... exceeds thr.\n",
    "# We can also guarantee some % error threshold, at the cost of computation time. Set err_thresh=0 to solve exactly.\n",
    "def pnj(thr, kjs, err_thresh=None):\n",
    "    # increase all j's by b    \n",
    "    ks = kjs[0]\n",
    "    js = (kjs[1]).astype(int)\n",
    "\n",
    "    # Check for simple situations\n",
    "    if thr <= 7 * np.sum(ks * js):\n",
    "        return 1\n",
    "    if thr > 10 * np.sum(ks*js):\n",
    "        return 0\n",
    "        \n",
    "    # Gaussian estimate\n",
    "    mu = 8.5 * np.sum(ks * js)\n",
    "    var = 5/4 * np.sum(ks*ks*js)        \n",
    "    p_est = scipy.special.erfc((thr - mu) / np.sqrt(2 * var)) / 2\n",
    "    \n",
    "    if err_thresh is None:\n",
    "        return p_est\n",
    "\n",
    "    # error estimate of Gaussian\n",
    "    err = np.amax(ks) / (2 * np.sqrt(2 * var))\n",
    "    max_err = err / p_est\n",
    "    if max_err <= err_thresh:\n",
    "        return p_est\n",
    "        \n",
    "    # Partially exact formulation\n",
    "    ktarg = err_thresh * p_est * (2 * np.sqrt(2 * var))\n",
    "    approx_select = ks < ktarg\n",
    "    ext = exact(ks[~approx_select], js[~approx_select])\n",
    "    \n",
    "    # Construct partial approximate distribution\n",
    "    ks, js = ks[approx_select], js[approx_select]\n",
    "    mu = 8.5 * np.sum(ks * js)\n",
    "    var = 5/4 * np.sum(ks*ks*js)\n",
    "    if var > 0:\n",
    "        p_est = lambda x: scipy.special.erfc((x - mu) / np.sqrt(2 * var)) / 2\n",
    "    else:\n",
    "        p_est = lambda x: 1 if x < 0 else 0\n",
    "    \n",
    "    # convolve exact distribution with approximate distribution\n",
    "    ptot = 0\n",
    "    for v, p in ext:\n",
    "        ptot += p * p_est(thr - v)\n",
    "    return ptot\n",
    "\n",
    "def subsum(z):\n",
    "    for i in range(z+1):\n",
    "        for j in range(z-i+1):\n",
    "            for k in range(z-i-j+1):\n",
    "                yield (i, j, k, z-i-j-k)\n",
    "\n",
    "def prob2(thresh, ks = (1), N=5, b=1, err=None):\n",
    "    reps = 0\n",
    "    ks = np.array(ks)\n",
    "    \n",
    "    ptot = 0\n",
    "    if len(ks) == 4:\n",
    "        it = subsum(N)\n",
    "    else:\n",
    "        it = filter(lambda x: sum(x) <= N, itertools.product(range(N+1), repeat=len(ks)))\n",
    "    for js in it:\n",
    "        js2 = np.array(js) + b\n",
    "        mn = multinom(*js, N=N)\n",
    "        if mn == 0: continue\n",
    "        if thresh <= 7*np.sum(ks * js2):\n",
    "            ptot += mn\n",
    "            continue\n",
    "        elif thresh > 10*np.sum(ks * js2):\n",
    "            continue\n",
    "\n",
    "        tmp = pnj(thresh, (ks, js2), err_thresh=err)\n",
    "        ptot += mn * tmp\n",
    "    return ptot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731770a8-5e33-4453-bf58-a3ed5bcb9434",
   "metadata": {},
   "source": [
    "A note on the `err` paramter. I typically leave it unconstrained because my approximation is constructed very well. I've also found a way to mathematically guarantee certain error bounds, which naturally makes the computation time suffer.\n",
    "\n",
    "For example, we could let `err=0.1` to guarantee that the returned result is within 10% of the true probability, or even `err=0` to force the program to find the exact probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19371bb-b290-436c-955c-a8bb63d064cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate P(100EM or 15CR): 0.4258741547179381\n",
      "Exact       P(100EM or 15CR): 0.4154639244079591\n"
     ]
    }
   ],
   "source": [
    "print(f'Approximate P(100EM or 15CR): {prob2(38.6, [.9, 1])}')\n",
    "print(f'Exact       P(100EM or 15CR): {prob2(38.6, [.9, 1], err=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3808b22f-5886-4e5d-8deb-76caaeeee6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627 µs ± 44.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit prob2(38.6, [.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c189480c-44fb-4449-b3f4-3c02ce8ce2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 ms ± 407 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit prob2(38.6, [.9, 1, .2, 1], err=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b13ef6-d72d-4154-b58b-ee7c0578a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906 µs ± 15.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit prob2(38.6, [.9, 1, .2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6ede4-bcf6-4f0a-a019-0d0e5e313465",
   "metadata": {},
   "source": [
    "### Type 2 Query on existing artifact\n",
    "Same as with Type 1 queries, we just need to shift the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6e0cd0-889b-4788-b52c-8d82e6053c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2_existing(thresh, ks, existing, rolls_left):\n",
    "    new_th = thresh\n",
    "    for ki, vi in zip(ks, existing):\n",
    "        new_th -= ki*vi\n",
    "    \n",
    "    return prob2(new_th, ks, N=rolls_left, b=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc02b13-7b23-4377-b979-9aea485fb1f5",
   "metadata": {},
   "source": [
    "## Connection to the Damage Formula\n",
    "The following couple blocks set up my damage evaluation schema, where I've manually filled in some standard(ish) values.\n",
    "\n",
    "All the percent- values are multiplied by 1000 for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c4dca34-603e-44aa-8a3f-9a2ae02e3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import artifact2\n",
    "import damage2\n",
    "import random\n",
    "from util.common import statnames, statmap, slotnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e36d8a0-0779-48ef-b9cb-9d7b7fd8b69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'damage2' from '/Users/albertxu/PycharmProjects/playground/Genshin/damage2.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(damage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221438a1-faac-4f6a-8ff9-3eb263fcef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats of lvl 90 Diona w/ protype crescent\n",
    "diona_stats = np.zeros(len(statnames))\n",
    "diona_stats[statmap['HP']] = 9570\n",
    "diona_stats[statmap['BaseATK']] = 722\n",
    "diona_stats[statmap['ATK%']] = 413\n",
    "diona_stats[statmap['DEF']] = 601\n",
    "diona_stats[statmap['CR']] = 50\n",
    "diona_stats[statmap['CD']] = 500\n",
    "diona_stats[statmap['ER']] = 1000\n",
    "diona_stats[statmap['Cryo']] = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889116df-0794-4336-963c-15ebb50af89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The artifacts I have equipped\n",
    "flower = np.zeros(len(statnames))\n",
    "flower[statmap['HP']] = 4780\n",
    "flower[statmap['ATK']] = 33\n",
    "flower[statmap['DEF']] = 16\n",
    "flower[statmap['EM']] = 82\n",
    "flower[statmap['CD']] = 140\n",
    "\n",
    "feather = np.zeros(len(statnames))\n",
    "feather[statmap['ATK']] = 311\n",
    "feather[statmap['ER']] = 162\n",
    "feather[statmap['DEF']] = 37\n",
    "feather[statmap['CR']] = 31\n",
    "feather[statmap['CD']] = 192\n",
    "\n",
    "sands = np.zeros(len(statnames))\n",
    "sands[statmap['EM']] = 187\n",
    "sands[statmap['HP']] = 538\n",
    "sands[statmap['DEF']] = 39\n",
    "sands[statmap['CR']] = 124\n",
    "sands[statmap['CD']] = 78\n",
    "\n",
    "cup = np.zeros(len(statnames))\n",
    "cup[statmap['Cryo']] = 466\n",
    "cup[statmap['HP%']] = 47\n",
    "cup[statmap['ATK%']] = 111\n",
    "cup[statmap['ER']] = 220\n",
    "cup[statmap['EM']] = 16\n",
    "\n",
    "hat = np.zeros(len(statnames))\n",
    "hat[statmap['CR']] = 311\n",
    "hat[statmap['HP']] = 299\n",
    "hat[statmap['CD']] = 155\n",
    "hat[statmap['ATK%']] = 105\n",
    "hat[statmap['EM']] = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "728b8478-4c53-43fc-b571-36a2dd9b9e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20080.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12170 * 1.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7eb6461-4e0d-4e26-a8c8-e34a8bee8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current damage per charged shot: 20761.071160967404\n"
     ]
    }
   ],
   "source": [
    "dmg = damage2.NormalDmg(2.23) * damage2.CritMult() * damage2.VapeMelt(1.5) * damage2.DmgBonus('Cryo')\n",
    "stats = diona_stats + flower + feather + sands + cup + hat\n",
    "print(f'Current damage per charged shot: {dmg.eval(stats)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c68ca0-2fdd-4425-b83b-b4f76079778a",
   "metadata": {},
   "source": [
    "## Queries for replacing an artifact (Contribution 2)\n",
    "Let's say I have a couple candidate artifacts to upgrade. All of them are EM sands, and they are all at lvl 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76bc2e46-1ed6-451a-98b2-518fb5df52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_stat(subs):\n",
    "    st = np.zeros(len(statnames))\n",
    "    for k, v in subs.items():\n",
    "        st[statmap[k]] = v * artifact2.sub_vals[k] / 10\n",
    "    return st\n",
    "\n",
    "# Want to beat this number\n",
    "sands0 = np.zeros(len(statnames))\n",
    "sands0[statmap['EM']] = 187\n",
    "\n",
    "stats = diona_stats + flower + feather + sands0 + cup + hat\n",
    "subs_orig = {'HP': 18, 'DEF': 17, 'CR': 32, 'CD': 10}\n",
    "dmg0 = dmg.eval(stats + to_stat(subs_orig))[0]\n",
    "\n",
    "# Finds linear approximation of 4x4 Hessian\n",
    "def appx_hessian2(H, k=1):\n",
    "    a = np.sum(H) + np.trace(H)\n",
    "    b = np.sum(H, axis=0) + np.diag(H)\n",
    "    \n",
    "    lhs = np.zeros(5)\n",
    "    lhs[1:] = k / 7 * (a + 2*b)\n",
    "    lhs[0] = k / 6 * a\n",
    "    \n",
    "    rhs_inv = 1 + np.eye(5)\n",
    "    rhs_inv[:,0] = -6\n",
    "    rhs_inv[0,:] = -k\n",
    "    rhs_inv[0,0] = 5*k\n",
    "    gv = rhs_inv @ lhs\n",
    "    return gv[0], gv[1:]\n",
    "\n",
    "# ixs must be length 3 or 4.\n",
    "def linearize(statz, ixs, rolls=5):\n",
    "    v, g, h = dmg.eval(statz)\n",
    "    ix_names = [statnames[ix] for ix in ixs]\n",
    "    scale = np.array([artifact2.sub_vals[k]/10 for k in ix_names])\n",
    "    \n",
    "    gnorm = g[ixs] * scale\n",
    "    hnorm = h[ixs][:,ixs] * np.outer(scale, scale)\n",
    "    \n",
    "    if len(ixs) == 3:\n",
    "        # force the thing to be 4x4.\n",
    "        gnorm = np.append(gnorm, 0)\n",
    "        hnorm = np.pad(hnorm, [0,1])\n",
    "        rolls_left = 4\n",
    "    \n",
    "    c0, h_lin = appx_hessian2(hnorm, k=10*rolls)\n",
    "    return v + c0, gnorm + h_lin / 2\n",
    "\n",
    "def eval_potential(new_subs, rolls=0):\n",
    "    rolls_left = 5 - rolls\n",
    "    if len(new_subs) == 3:\n",
    "        rolls_left = 4\n",
    "    \n",
    "    ix = [statmap[k] for k in new_subs]\n",
    "    c, m = linearize(stats + to_stat(new_subs), ix, rolls_left)\n",
    "    return prob2(dmg0 - c, m, N=rolls_left, b=0, err=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7434d7d-6911-4562-834d-1e8cb3ae0914",
   "metadata": {},
   "source": [
    "### Testing the maths\n",
    "The validity of my maths are evaluated by upgrading some un-upgraded artifact 10,000 times and comparing the predicted probability with the observed probability.\n",
    "\n",
    "The runtime of evaluating the potential of an un-upgraded artifact suffers a little bit. I don't know what exactly counts as acceptible, but it's around the 2ms mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3428edeb-5efb-475c-ac49-1d2b5ff9b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgrade_artifact(subs_init, nn=5):\n",
    "    up_locs = np.random.randint(4, size=nn)\n",
    "    up_vals = np.random.randint(7, 11, size=nn)\n",
    "    \n",
    "    new_subs = {}\n",
    "    for i, k in enumerate(subs_init):\n",
    "        new_subs[k] = up_vals[up_locs == i].sum() + subs_init[k]\n",
    "    return new_subs\n",
    "\n",
    "def check_probability(subs, N=1000):\n",
    "    num_ups = 5 - (4 - len(subs))\n",
    "    test_vals = [dmg.eval(stats + to_stat(upgrade_artifact(subs, nn=num_ups)))[0] for _ in range(N)]\n",
    "    return np.count_nonzero(np.array(test_vals) > dmg0) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c2e6fc8-c38e-445d-8447-abf9ecda9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretend all of these are unupgraded EM main-stat sands.\n",
    "sub1 = {'CD': 7, 'HP': 9, 'ATK%': 8, 'ATK': 7}\n",
    "sub2 = {'CD': 8, 'CR': 9, 'HP': 10, 'ATK': 7}\n",
    "sub3 = {'CD': 10, 'CR': 10, 'ATK%': 9}\n",
    "sub4 = {'ATK': 8, 'DEF': 10, 'ATK%': 9, 'HP': 9}\n",
    "sub5 = {'ATK': 7, 'ATK%': 10, 'CR': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae38e98-d1e0-419f-b236-1b97b422a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math predictions:\t0.04525003754460953\n",
      "Simulated Value:\t0.0447\n"
     ]
    }
   ],
   "source": [
    "print(f'Math predictions:\\t{eval_potential(sub4)}')\n",
    "print(f'Simulated Value:\\t{check_probability(sub4, N=10000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b88d943-b769-4abb-83f2-74aee9b5e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 ms ± 42.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit eval_potential(sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c264705-b4eb-4b54-b2f9-3cef1f7e6347",
   "metadata": {},
   "source": [
    "## Querying \"completeness\" of artifact set (Contribution 3)\n",
    "We can design another query type that gives the expected amount of time it would take to improve upon your current set's total DPS. \n",
    "\n",
    "For each slot (flower, feather, etc.) and main stat (ATK%, EM, HP%, etc.) we can compute the probability that a random new artifact, once upgraded to max, will improve upon the current set's total DPS. Then we can take the weighted average of these probabilities to be the total probability that a new artifact will improve the set's DPS. The expected time we would need to farm to improve DPS is then the inverse of the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "544d59aa-b8fd-4d14-9442-964a15ebd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_subs_summary = {\n",
    "0: {\n",
    "    (4, 6, 6, 6): 31833 / 2351440, (3, 6, 6, 6): 35150679 / 3618174560,\n",
    "    (4, 4, 6, 6): 12247 / 1492260, (3, 4, 6, 6): 6395431221 / 1085396703776, (3, 3, 6, 6): 588789 / 139160560,\n",
    "    (4, 4, 4, 6): 4249 / 852720, (3, 4, 4, 6): 83731933 / 23392170340, (3, 3, 4, 6): 53217 / 20691880,\n",
    "    (4, 4, 4, 4): 1 / 330, (3, 4, 4, 4): 17447 / 8009760, (3, 3, 4, 4): 50647 / 32339406,\n",
    "},\n",
    "6: {\n",
    "    (4, 4, 6, 6): 222877 / 12932920, (3, 4, 6, 6): 1724981913 / 140744203600,  (3, 3, 6, 6): 80433 / 9225944,\n",
    "    (4, 4, 4, 6): 2407 / 235144, (3, 4, 4, 6): 15233623 / 2090714400, (3, 3, 4, 6): 3427272 / 660607675,\n",
    "    (4, 4, 4, 4): 128 / 20995, (3, 4, 4, 4): 35624 / 8200647, (3, 3, 4, 4): 7813 / 2523276,\n",
    "},\n",
    "4: {\n",
    "    (4, 6, 6, 6): 29 / 1309, (3, 6, 6, 6): 4745547 / 300284600,\n",
    "    (4, 4, 6, 6): 1475 / 111384, (3, 4, 6, 6): 1824571 / 193040100, (3, 3, 6, 6): 92097 / 13649300,\n",
    "    (4, 4, 4, 6): 589 / 74256, (3, 4, 4, 6): 1979168149 / 349325364960, (3, 3, 4, 6): 16088 / 3974355,\n",
    "    (4, 4, 4, 4): 1 / 210, (3, 4, 4, 4): 27001 / 7931616, (3, 3, 4, 4): 70339 / 28893744,\n",
    "},\n",
    "3: {\n",
    "    (4, 6, 6, 6): 106873344 / 5489226575, (3, 6, 6, 6): 5262165 / 378263704,\n",
    "    (4, 4, 6, 6): 39435776 / 3375362925, (3, 4, 6, 6): 66962957661 / 8017134743800,\n",
    "    (4, 4, 4, 6): 33193984 / 4725508095, (3, 4, 4, 6): 151137649 / 30075647580,\n",
    "    (4, 4, 4, 4): 2048 / 483923, (3, 4, 4, 4): 2368048 / 781535645,\n",
    "}}\n",
    "\n",
    "def p_subs(vs, main_type):\n",
    "    srch_key = tuple(sorted(map(lambda s: artifact2.substat.distr[s], vs)))\n",
    "    if main_type not in artifact2.substat.distr:\n",
    "        return prob_subs_summary[0][srch_key]\n",
    "    return prob_subs_summary[artifact2.substat.distr[main_type]][srch_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "897072d1-3b75-488d-b6f3-8915975099e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = diona_stats + flower + feather + cup + hat\n",
    "dmg0 = dmg.eval(stats + sands)[0]\n",
    "def prob_beat(main, subs, p3sub=.8):\n",
    "    ix = [statmap[s] for s in subs]\n",
    "    sand0 = np.zeros(len(statnames))\n",
    "    sand0[statmap[main]] = artifact2.main_vals[main]\n",
    "    c, m = linearize(stats + sand0, ix, rolls=9)\n",
    "    pp3sub = p3sub * prob2(dmg0 - c, m, N=4, b=1, err=None)\n",
    "    pp4sub = (1-p3sub) * prob2(dmg0 - c, m, N=5, b=1, err=None)\n",
    "    return pp3sub + pp4sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0f076d9-205b-4ef9-a469-9a2364f4b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artis = [flower, feather, sands, cup, hat]\n",
    "def evaluate_slot(slot):\n",
    "    global dmg0\n",
    "    global stats\n",
    "    stats = diona_stats + sum([a for i, a in enumerate(artis) if i != slot])\n",
    "    dmg0 = dmg.eval(stats + artis[slot])[0]\n",
    "    \n",
    "    ptot = 0\n",
    "    main_distr = artifact2.mainstat[slot].distr\n",
    "    main_denom = sum(main_distr.values())\n",
    "    for main, v_main in main_distr.items():\n",
    "        p_main = v_main / main_denom\n",
    "        sub_distr = artifact2.substat\n",
    "        sub_distr = sub_distr.remove(main)\n",
    "        for c in itertools.combinations(sub_distr.k, 4):\n",
    "            prb = p_main * p_subs(c, main)\n",
    "            ptot += prb * prob_beat(main, c, p3sub=.8)\n",
    "    return ptot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7d19e-f8c6-453b-9d16-a2c9cf51d25e",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "The function `evaluate_slot` returns an estimate of the probability that a random new flower/feather/etc. will beat the current set's total damage value. It's a rather slow function, taking a couple seconds to run depending on the number of options that the main stat can take on. Evaluating all 5 artifact slots takes about 10 seconds to run in total on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7de3c59d-45be-4104-8bde-9afbf9193949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower - 0.03970803290118193\n",
      "Feath - 0.28305707787509365\n",
      "Sands - 0.04127033545386591\n",
      "Cup - 0.024475889785761824\n",
      "Hat - 0.0006308605765661203\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'{slotnames[i]} - {evaluate_slot(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "554a69c4-b265-4da1-81d6-71936ce84cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38 s ± 701 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit evaluate_slot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60203d-d78c-4898-a057-7c7e0508c460",
   "metadata": {},
   "source": [
    "We can compare the above predictions to estimates of the actual value by making random artifacts below, using Monte-Carlo approach.\n",
    "\n",
    "The (above) estimates are off by imo an acceptable amount, typically somewhere within 1% of the (below) true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05a4855e-0726-49fd-a16d-1082ffef39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalboi(slot, N=1000):\n",
    "    stats = diona_stats + sum([a for i, a in enumerate(artis) if i != slot])\n",
    "    dmg0 = dmg.eval(stats + artis[slot])[0]\n",
    "    \n",
    "    num_exc = 0\n",
    "    for _ in range(N):\n",
    "        a = artifact2.make_arti(slot=slot).tostat()\n",
    "        dmg2 = dmg.eval(stats + a)[0]\n",
    "        if dmg2 > dmg0:\n",
    "            num_exc += 1\n",
    "    return num_exc / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2b2ae10-98b4-491e-a1ea-a8f64a2958fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower - 0.05313333333333333\n",
      "Feath - 0.29086666666666666\n",
      "Sands - 0.046066666666666665\n",
      "Cup - 0.025333333333333333\n",
      "Hat - 0.0010666666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'{slotnames[i]} - {evalboi(i, N=15000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c659a56-001c-4ea8-8eaa-4a730be5c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower - 0.05006666666666667\n",
      "Feath - 0.29973333333333335\n",
      "Sands - 0.04273333333333333\n",
      "Cup - 0.0232\n",
      "Hat - 0.001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'{slotnames[i]} - {evalboi(i, N=15000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc7b87-5d3b-4e75-bf56-82733f2d16b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
